# -*- coding: utf-8 -*-
"""DEEP1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QJ7lxv3FL0ql8EmrFmlk_Dan12zBZM8F
"""

# import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

data = pd.read_csv('/content/FuelConsumptionCo2.csv')
data.head()

data.info()

data = data.drop_duplicates()

num = data.select_dtypes(include='number')
num.head()

from tensorflow.keras.utils import to_categorical

data['MODELYEAR'] = to_categorical(data[['MODELYEAR']])

for col in num:
  print(col)
  sns.histplot(num[col])
  plt.show()
  print("="*12)

num.columns

log= ['FUELCONSUMPTION_CITY' ,'FUELCONSUMPTION_COMB',]
for col in log:
  data[col] = np.log(data[col])

for col in log:
  sns.histplot(data[col])
  plt.show()
  print("="*12)

for col in num:
  sns.boxplot(data[col])
  plt.show()
  print("="*12)

cat = data.select_dtypes(include='object')
cat.head()

for col in cat:
  print(col)
  print(cat[col].value_counts())
  print("="*12)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in cat:
  data[col] = le.fit_transform(data[col])

data

data.isna().sum()

data

from sklearn.model_selection import train_test_split
X = data.drop('CO2EMISSIONS', axis=1)
y = data['CO2EMISSIONS']

x_train , x_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=100)



from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
for col in x_train.columns:
  if x_train[col].dtype in ['int64', 'float64']: # Only scale numerical columns
    x_train[col] = scaler.fit_transform(x_train[[col]])
    x_test[col] = scaler.transform(x_test[[col]])

x_train.head()

# use deeplearning for regression to predict 'CO2EMISSIONS'

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

model = Sequential()
model.add(Dense(128, input_dim=x_train.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='linear'))

model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))

early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')

history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])
print(model.summary())

# ACCURACY
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

# predict
y_pred = model.predict(x_test)
from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error:", mse)
print("R-squared:", r2)

model_visualization = keras.utils.plot_model(model, to_file='model_visualization.png', show_shapes=True, show_layer_names=True)

# model nisualisation
from IPython.display import Image
Image(retina=True, filename='model_visualization.png')

print(r2)

# save model
import joblib
joblib.dump(model, 'model.pkl')

